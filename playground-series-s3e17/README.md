### Description of the competition

https://www.kaggle.com/competitions/playground-series-s3e17        
Синтетические данные.    
Задача бинарной классификации. Метрика roc_auc.Метрика очень высокая  у лидеров 0,98 и выше.    
Дисбаланс классов 1: 0.0169.  Строк 130к.    
   
Столбы пару катег фичей,причем в одном стобце около 10 000 категорий, осталные числ.  
### Intuition
Используем кросс валидацию.    
Берем  градиент бустинги.    
Прогоним дефолтные catboost, lgbm, xgb  
Посмотрим выбросы и их влияние на метрики дефолтных catboost, lgbm.    
Оценим feture imp. и их влияние на метрики дефолтных моделек.    
Затем поиск гиперпараметров , используя optuna.   
След шаг блендинг моделей.

### Approach     
Написаны функц преобразования датасетов для каждой модели.
И функции моделей с разными параметрами.     
Это позволяет упростить код и составить список моделей_функц и идити по нему в циклах .      
Найдены гипер параметры для моделей используя optuna.    
Тестирвоались нейросетка DatRetClassifier, но результат на скоре был гораздо хуже бустингов.  

Для блендинга написан код Blend Machine  - это самое полезное тут:  
 - Использя StratifiedKFold в цикле идет кроссвалидация всех моделей из списка, который легко менять/отключать.  
 - Результаты predict_proba и таргеты  записываются в словарь списков.  
 - Затем из predcit_proba  создается матрица фичей для RidgeClassifier,в котором используятся метод наименьших квадратов. 
 - Используя .coef_ получаем веса моделей для каждого фолда, усредняем и получаем итоговые веса для использования на тест данных.

Так же тестировался метод scipy.optimize.minimize для блендинга, stacking, но  резульат был по хуже блендинга наDatRetClassifier.  

На открытом лидерборде был на 248 месте, скор не шел, был практически равен соло catboost дефолт и у меня кончилось время GPU в колабе  и время в реале))  
Но на привате улетел вверх аж на + 202  и занял 42 позицию . Блендинг оказался качественный. 

![image](https://github.com/ivan74rus/kaggle/assets/117063726/5634d674-9584-41fc-a28d-d688e5294677)

Лучший скор показал блендинг cat default + cat params + lgbm default + lgbm params.    

Для улучшения дальнейших результатов  на след сорев. нужно увеличивать кол-во различных моделей на разных парамтерах фичах итд.  Сразу приступать к блендингу. Сравнивать с  optimize.minimize  
Дописать автоматический перебор всех возможных сочетаний моделий и  бленда их predict_proba.   
задачка неоч простая. возмодно придется пересмотреть спосбо сохранения на цикле кроссвалидации predict_proba моделей.
